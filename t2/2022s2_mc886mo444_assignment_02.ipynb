{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs9E_R5yD48u"
   },
   "source": [
    "# **Assignment \\#2**: Machine Learning MC886/MO444\n",
    "University of Campinas (UNICAMP), Institute of Computing (IC)\n",
    "\n",
    "Prof. Sandra Avila, 2022s2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFS9Oum_RJX9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139373: Cinthia Cristina Calchi Kleiner\n",
      "103897: Randerson A. Lemos\n"
     ]
    }
   ],
   "source": [
    "# TODO: RA & Name \n",
    "print('139373: ' + 'Cinthia Cristina Calchi Kleiner')\n",
    "print('103897: ' + 'Randerson A. Lemos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVGH2s7fD_03"
   },
   "source": [
    "## Objective\n",
    "\n",
    "Explore **linear regression** and **logistic regression** alternatives and come up with the best possible model for the problems, avoiding overfitting. In particular, predict the performance of students from public schools in the state of São Paulo based on socioeconomic data from SARESP (School Performance Assessment System of the State of São Paulo, or Sistema de Avaliação de Rendimento Escolar do Estado de São Paulo) 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3XDZRGqEwsk"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "These data were aggregated from [Open Data Platform of the Secretary of Education of the State of São Paulo](https://dados.educacao.sp.gov.br/) (*Portal de Dados Abertos da Secretaria da Educação do Estado de São Paulo*). The dataset is based on two data sources: [SARESP questionnaire](https://dados.educacao.sp.gov.br/dataset/question%C3%A1rios-saresp) and [SARESP test](https://dados.educacao.sp.gov.br/dataset/profici%C3%AAncia-do-sistema-de-avalia%C3%A7%C3%A3o-de-rendimento-escolar-do-estado-de-s%C3%A3o-paulo-saresp-por), conducted in 2021 with students from the 5th and 9th year of Primary School and 3rd year of Highschool. The questionnaire comprehends 63 socio-economical questions, and it is available at the [link](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing)), and the test is composed of questions of Portuguese, Mathematics, and Natural Sciences.\n",
    "\n",
    "\n",
    "**Data Dictionary**:\n",
    "\n",
    "- **CD_ALUNO**: Student ID;\n",
    "\n",
    "- **CODESC**: School ID;\n",
    "\n",
    "- **NOMESC**: School Name;\n",
    "\n",
    "- **RegiaoMetropolitana**: Metropolitan region;\n",
    "\n",
    "- **DE**: Name of the Education Board;\n",
    "\n",
    "- **CODMUN**: City ID;\n",
    "\n",
    "- **MUN**: City name;\n",
    "\n",
    "- **SERIE_ANO**: Scholar year;\n",
    "\n",
    "- **TURMA**: Class;\n",
    "\n",
    "- **TP_SEXO**: Sex (Female/Male);\n",
    "\n",
    "- **DT_NASCIMENTO**: Birth date;\n",
    "\n",
    "- **PERIODO**: Period of study (morning, afternoon, evening);\n",
    "\n",
    "- **Tem_Nec**: Whether student has any special needs (1 = yes, 0 = no);\n",
    "\n",
    "- **NEC_ESP_1** - **NEC_ESP_5**: Student disabilities;\n",
    "\n",
    "- **Tipo_PROVA**: Exam type (A = Enlarged, B = Braile, C = Common);\n",
    "\n",
    "- **QN**: Student answer to the question N (N= 1, ... , 63), see  questions in [questionnaire](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing));\n",
    "\n",
    "- **porc_ACERT_lp**: Percentage of correct answers in the Portuguese test;\n",
    "\n",
    "- **porc_ACERT_MAT**: Percentage of correct answers in the Mathematics test;\n",
    "\n",
    "- **porc_ACERT_CIE**: Percentage of correct answers in the Natural Sciences test;\n",
    "\n",
    "- **nivel_profic_lp**: Proficiency level in the Portuguese test;\n",
    "\n",
    "- **nivel_profic_mat**: Proficiency level in the Mathematics test;\n",
    "\n",
    "- **nivel_profic_cie**:  Proficiency level in the Natural Sciences test.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "You must respect the following training/test split:\n",
    "- SARESP_train.csv\n",
    "- SARESP_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FAA8hsZUseO"
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "This part of the assignment aims to predict students' performance on Portuguese, Mathematics, and Natural Sciences tests (target values: `porc_ACERT_lp`, `porc_ACERT_MAT`, and  `porc_ACERT_CIE`) based on their socioeconomic data. Then, at this point, you have to **drop the columns `nivel_profic_lp`, `nivel_profic_mat`** and **`nivel_profic_cie`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d495CmpCltx"
   },
   "source": [
    "### Activities\n",
    "\n",
    "1. (3.5 points) Perform Linear Regression. You should implement your solution and compare it with ```sklearn.linear_model.SGDRegressor``` (linear model fitted by minimizing a regularized empirical loss with SGD, http://scikit-learn.org). Keep in mind that friends don't let friends use testing data for training :-)\n",
    "\n",
    "Note: Before we start an ML project, we always conduct a brief exploratory analysis :D \n",
    "\n",
    "Some factors to consider: Are there any outliers? Are there missing values? How will you handle categorical variables? Are there any features with low correlation with the target variables? What happens if you drop them?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3y0QxxH1KgE1"
   },
   "outputs": [],
   "source": [
    "# TODO: Load and preprocess your dataset.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# df=pd.read_csv(\"assets/SARESP_train.csv\")\n",
    "# columns = set(df.columns) - set(['nivel_profic_lp', 'nivel_profic_mat', 'nivel_profic_cie'])\n",
    "# df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17389/3974539728.py:2: DtypeWarning: Columns (78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"assets/SARESP_train.csv\"\n",
    "df=pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the df.shape method, it is possible to see that the dataframe has 120596 lines and 88 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120596, 88)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the first lines of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_ALUNO</th>\n",
       "      <th>NOMESC</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>...</th>\n",
       "      <th>NEC_ESP_4</th>\n",
       "      <th>NEC_ESP_5</th>\n",
       "      <th>Tipo_PROVA</th>\n",
       "      <th>Tem_Nec</th>\n",
       "      <th>porc_ACERT_lp</th>\n",
       "      <th>porc_ACERT_MAT</th>\n",
       "      <th>porc_ACERT_CIE</th>\n",
       "      <th>nivel_profic_lp</th>\n",
       "      <th>nivel_profic_mat</th>\n",
       "      <th>nivel_profic_cie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26270013</td>\n",
       "      <td>JULIO FORTES</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>41.7</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30756614</td>\n",
       "      <td>MESSIAS FREIRE PROFESSOR</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>Adequado</td>\n",
       "      <td>Avançado</td>\n",
       "      <td>Adequado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26014872</td>\n",
       "      <td>JOSE CONTI</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>37.5</td>\n",
       "      <td>54.2</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Básico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25739025</td>\n",
       "      <td>NAPOLEAO DE CARVALHO FREIRE PROFESSOR</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>29.2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27363009</td>\n",
       "      <td>RESIDENCIAL BORDON</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>41.7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Adequado</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "      <td>Básico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29106659</td>\n",
       "      <td>ANA MESQUITA LAURINI</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>66.7</td>\n",
       "      <td>70.8</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Básico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26920670</td>\n",
       "      <td>HERBERT BALDUS</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>62.5</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "      <td>Básico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23566650</td>\n",
       "      <td>TEOFILO DE ANDRADE DOUTOR</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>83.3</td>\n",
       "      <td>79.2</td>\n",
       "      <td>Adequado</td>\n",
       "      <td>Adequado</td>\n",
       "      <td>Adequado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29849774</td>\n",
       "      <td>FERNANDO BRASIL PROF</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>41.7</td>\n",
       "      <td>20.8</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "      <td>Básico</td>\n",
       "      <td>Abaixo do Básico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32568405</td>\n",
       "      <td>ASTROGILDO SILVA PROFESSOR</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>Adequado</td>\n",
       "      <td>Adequado</td>\n",
       "      <td>Adequado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CD_ALUNO                                 NOMESC Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8  \\\n",
       "0  26270013                           JULIO FORTES  B  E  E  E  E  E  E  E   \n",
       "1  30756614               MESSIAS FREIRE PROFESSOR  B  D  E  C  E  E  E  E   \n",
       "2  26014872                             JOSE CONTI  B  E  B  D  E  B  D  C   \n",
       "3  25739025  NAPOLEAO DE CARVALHO FREIRE PROFESSOR  B  D  E  D  C  E  D  D   \n",
       "4  27363009                     RESIDENCIAL BORDON  B  D  E  E  E  E  E  C   \n",
       "5  29106659                   ANA MESQUITA LAURINI  B  C  D  C  C  D  C  C   \n",
       "6  26920670                         HERBERT BALDUS  B  E  D  E  E  C  E  E   \n",
       "7  23566650              TEOFILO DE ANDRADE DOUTOR  A  E  D  D  D  D  D  C   \n",
       "8  29849774                   FERNANDO BRASIL PROF  A  E  E  E  E  E  E  E   \n",
       "9  32568405             ASTROGILDO SILVA PROFESSOR  B  E  D  D  E  E  E  D   \n",
       "\n",
       "   ... NEC_ESP_4 NEC_ESP_5 Tipo_PROVA Tem_Nec porc_ACERT_lp porc_ACERT_MAT  \\\n",
       "0  ...       NaN       NaN          C       0          41.7           20.8   \n",
       "1  ...       NaN       NaN          C       0          83.3          100.0   \n",
       "2  ...       NaN       NaN          C       0          58.3           37.5   \n",
       "3  ...       NaN       NaN          C       0          29.2           29.2   \n",
       "4  ...       NaN       NaN          C       0          79.2           41.7   \n",
       "5  ...       NaN       NaN          C       0          66.7           66.7   \n",
       "6  ...       NaN       NaN          C       0          50.0           16.7   \n",
       "7  ...       NaN       NaN          C       0          87.5           83.3   \n",
       "8  ...       NaN       NaN          C       0          29.2           41.7   \n",
       "9  ...       NaN       NaN          C       0          75.0           75.0   \n",
       "\n",
       "  porc_ACERT_CIE   nivel_profic_lp  nivel_profic_mat  nivel_profic_cie  \n",
       "0           20.8  Abaixo do Básico  Abaixo do Básico  Abaixo do Básico  \n",
       "1           66.7          Adequado          Avançado          Adequado  \n",
       "2           54.2            Básico            Básico            Básico  \n",
       "3           16.7  Abaixo do Básico  Abaixo do Básico  Abaixo do Básico  \n",
       "4           50.0          Adequado  Abaixo do Básico            Básico  \n",
       "5           70.8            Básico            Básico            Básico  \n",
       "6           62.5            Básico  Abaixo do Básico            Básico  \n",
       "7           79.2          Adequado          Adequado          Adequado  \n",
       "8           20.8  Abaixo do Básico            Básico  Abaixo do Básico  \n",
       "9           66.7          Adequado          Adequado          Adequado  \n",
       "\n",
       "[10 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was to visualize the percentage of the number of missing data in each dataframe column. The following code show us the columns that have a null values percentage greater than zero.The variables NEC_ESP_1, NEC_ESP_2 , NEC_ESP_2, NEC_ESP_4 and NEC_ESP_5 do not own 98% of their data. So, these variables will not be considered int the data modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: NEC_ESP_1, Null Values Percentage: 98.01817639059338\n",
      "Column Name: NEC_ESP_2, Null Values Percentage: 99.91127400577133\n",
      "Column Name: NEC_ESP_3, Null Values Percentage: 99.93697966765068\n",
      "Column Name: NEC_ESP_4, Null Values Percentage: 99.99917078510066\n",
      "Column Name: NEC_ESP_5, Null Values Percentage: 100.0\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    na_percentage = df[col].isna().sum() / df.shape[0] * 100\n",
    "    if na_percentage > 0:\n",
    "        print(f'Column Name: {col}, Null Values Percentage: {na_percentage}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose, the cited columns will be deleteded from the data. The CD_ALUNO variable will also be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['NEC_ESP_1', 'NEC_ESP_2', 'NEC_ESP_3', 'NEC_ESP_4', 'NEC_ESP_5', 'CD_ALUNO'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODMUN</th>\n",
       "      <th>CODESC</th>\n",
       "      <th>Tem_Nec</th>\n",
       "      <th>porc_ACERT_lp</th>\n",
       "      <th>porc_ACERT_MAT</th>\n",
       "      <th>porc_ACERT_CIE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>364.349075</td>\n",
       "      <td>279415.870510</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>60.151213</td>\n",
       "      <td>52.225829</td>\n",
       "      <td>56.928877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>220.098318</td>\n",
       "      <td>394245.824543</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>21.730825</td>\n",
       "      <td>21.262466</td>\n",
       "      <td>18.441383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>15568.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.700000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>45.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>336.000000</td>\n",
       "      <td>35178.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>58.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>582.000000</td>\n",
       "      <td>901573.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.200000</td>\n",
       "      <td>66.700000</td>\n",
       "      <td>70.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>793.000000</td>\n",
       "      <td>926103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CODMUN         CODESC        Tem_Nec  porc_ACERT_lp  \\\n",
       "count  120596.000000  120596.000000  120596.000000  120596.000000   \n",
       "mean      364.349075  279415.870510       0.019818      60.151213   \n",
       "std       220.098318  394245.824543       0.139376      21.730825   \n",
       "min       100.000000      24.000000       0.000000       0.000000   \n",
       "25%       100.000000   15568.000000       0.000000      41.700000   \n",
       "50%       336.000000   35178.000000       0.000000      62.500000   \n",
       "75%       582.000000  901573.000000       0.000000      79.200000   \n",
       "max       793.000000  926103.000000       1.000000     100.000000   \n",
       "\n",
       "       porc_ACERT_MAT  porc_ACERT_CIE  \n",
       "count   120596.000000   120596.000000  \n",
       "mean        52.225829       56.928877  \n",
       "std         21.262466       18.441383  \n",
       "min          0.000000        0.000000  \n",
       "25%         37.500000       45.800000  \n",
       "50%         50.000000       58.300000  \n",
       "75%         66.700000       70.800000  \n",
       "max        100.000000      100.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    0.523135\n",
       "M    0.476865\n",
       "Name: TP_SEXO, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TP_SEXO'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Região Metropolitana de São Paulo                          0.393355\n",
       "Interior                                                   0.325143\n",
       "Região Metropolitana do Vale do Paraíba e Litoral Norte    0.077507\n",
       "Região Metropolitana da Baixada Santista                   0.063750\n",
       "Região Metropolitana de Sorocaba                           0.055856\n",
       "Região Metropolitana de Ribeirão Preto                     0.055657\n",
       "Região Metropolitana de Campinas                           0.028732\n",
       "Name: RegiaoMetropolitana, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RegiaoMetropolitana'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_hist_plots(n_lines, n_coluns, columns_names):\n",
    "    '''\n",
    "    Multiple plots histograms based on columns names\n",
    "    Args:\n",
    "        n_lines: number of lines in subplots\n",
    "        n_columns: number of columns in subplots\n",
    "        columns_names: list of columns names\n",
    "    Returns:\n",
    "        Seaborn histogram subplots\n",
    "    '''\n",
    "    \n",
    "    fig, axes = plt.subplots(n_lines,n_coluns, figsize=(10,4))\n",
    "    for i,column_name in enumerate(columns_names):\n",
    "        sns.histplot(data=df[column_name], binwidth=10, kde=True, ax=axes[i]).set(title=column_name)\n",
    "        fig.axes[i].axvline(x=df[column_name].median(), color='red', ls='--', lw=2.5)\n",
    "        \n",
    "    \n",
    "    plt.setp(axes, yticks=[])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfig\u001b[49m,axes[i]\u001b[38;5;241m.\u001b[39mtext(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, horizontalalignment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemibold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fig' is not defined"
     ]
    }
   ],
   "source": [
    "fig,axes[i].text(10, 300, \"median\", horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_multiple_hist_plots = multiple_hist_plots(1,3,['porc_ACERT_MAT','porc_ACERT_lp','porc_ACERT_CIE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the analysis of the data from the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical into numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "columns_names = df.columns.to_list()\n",
    "column_object_names = []\n",
    "for column_name in columns_names:\n",
    "    if df[str(column_name)].dtype == object:\n",
    "        df[str(column_name)] = le.fit_transform(df[str(column_name)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the target variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the preprocessing step, it is necessary to define the target values. For this purporse, the X structure will be composed by all columns except the target variables.While the y structure will be composed only by the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.reset_index(inplace=True)\n",
    "X = df.drop(['nivel_profic_lp', 'nivel_profic_mat','nivel_profic_cie'],axis=1)\n",
    "y = df[['nivel_profic_lp', 'nivel_profic_mat', 'nivel_profic_cie']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Split:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate our training step, we devided the data into train and validation sets with 80 and 20% of the data respectivily. For this, we used the train_test_split fucntion from sklearn and we set a random_state in order to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y,test_size=0.20,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_columns = set(['porc_ACERT_lp', 'porc_ACERT_MAT', 'porc_ACERT_CIE'])\n",
    "# featur_columns = columns - target_columns\n",
    "\n",
    "# features = df[featur_columns]\n",
    "# targets = df[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9cpdif9JxFR"
   },
   "outputs": [],
   "source": [
    "# TODO: Linear Regression. Implement your solution. You cannot use scikit-learn, Keras/TensorFlow, or PyTorch libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4nZrMr_C2X7"
   },
   "outputs": [],
   "source": [
    "# TODO: Linear Regression. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model, it is necessary to create an object o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object of the model\n",
    "model = LinearRegression()\n",
    "#Fitting the model with the trainning data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Model intercept value : {model.intercept_}')\n",
    "print(f' Coeficients : {model.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the values of the y_val set with the x_val data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean squared error: {mean_squared_error(y_val, y_pred)}\")\n",
    "print(f\"Coefficient of determination: {r2_score(y_val, y_pred)}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBNZQNImKQeo"
   },
   "source": [
    "\n",
    "> What are the conclusions? (1-2 paragraphs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADxPBRhuK_Vq"
   },
   "source": [
    "2. (1 point) Use different Gradient Descent (GD) learning rates when optimizing. Compare the GD-based solutions with Normal Equation. What are the conclusions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSZ1pLItNVbU"
   },
   "outputs": [],
   "source": [
    "# TODO: Gradient Descent (GD) with 3 different learning rates. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrPl7jKgJPW6"
   },
   "source": [
    "\n",
    "3. (0.75 point) Sometimes, we need some more complex function to make good prediction. Devise and evaluate a Polynomial Linear Regression model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjGbg41PMHR9"
   },
   "outputs": [],
   "source": [
    "# TODO: Complex model. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBLKtosaLaCw"
   },
   "source": [
    "*texto em itálico*\n",
    " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldSh1vtWK5Zk"
   },
   "source": [
    "4. (0.5) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg7aNkl_LG4P"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the cost function vs. number of iterations in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfR862UoK9j6"
   },
   "outputs": [],
   "source": [
    "*texto em itálico*\n",
    " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xij-E5UUseS"
   },
   "source": [
    "5. (0.25 point) Pick **your best model**, based on your validation set, and predict the target values for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_PobUahUseS"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCJuwjrAUseS"
   },
   "source": [
    "Now, this part of the assignment aims to predict students' proeficiency level on Portuguese, Mathematics, and Natural Sciences (target values: `nivel_profic_lp`, `nivel_profic_mat` and `nivel_profic_cie`) based on their socioeconomic data. Then, you have to **drop the columns `porc_ACERT_lp`,  `porc_ACERT_MAT`** and  **`porc_ACERT_CIE`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joYtn8avUseS"
   },
   "source": [
    "### Activities\n",
    "\n",
    "1. (2.75 points) Perform Multinomial Logistic Regression (_i.e._, softmax regression). It is a generalization of Logistic Regression to the case where we want to handle multiple classes. Try different combinations of features, dropping the ones less correlated to the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-36Dt2V_UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Multinomial Logistic Regression. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQj3oImUUseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb1KNEqLUseT"
   },
   "source": [
    "2. (0.5 point) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfECeHi3UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the cost function vs. number of iterations in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IM4mx23UseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqlv9-6OUseT"
   },
   "source": [
    "3. (0.75 point) Pick **your best model** and plot the confusion matrix in the **test set**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jdyJuS0UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the confusion matrix. You can use scikit-learn, seaborn, matplotlib libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAmCj0cpUseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdSGS4brHnAi"
   },
   "source": [
    "## Deadline\n",
    "\n",
    "Monday, September 19, 11:59 pm. \n",
    "\n",
    "Penalty policy for late submission: You are not encouraged to submit your assignment after due date. However, in case you do, your grade will be penalized as follows:\n",
    "- September 20, 11:59 pm : grade * 0.75\n",
    "- September 21, 11:59 pm : grade * 0.5\n",
    "- September 22, 11:59 pm : grade * 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joN9pvZJIfW5"
   },
   "source": [
    "## Submission\n",
    "\n",
    "On Google Classroom, submit your Jupyter Notebook (in Portuguese or English).\n",
    "\n",
    "**This activity is NOT individual, it must be done in pairs (two-person group).**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
