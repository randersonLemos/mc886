{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs9E_R5yD48u"
   },
   "source": [
    "# **Assignment \\#2**: Machine Learning MC886/MO444\n",
    "University of Campinas (UNICAMP), Institute of Computing (IC)\n",
    "\n",
    "Prof. Sandra Avila, 2022s2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFS9Oum_RJX9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA1: Cinthia Kleiner\n",
      "103897: Randerson A. Lemos\n"
     ]
    }
   ],
   "source": [
    "# TODO: RA & Name \n",
    "print('139373: ' + 'Cinthia Kleiner')\n",
    "print('103897: ' + 'Randerson A. Lemos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVGH2s7fD_03"
   },
   "source": [
    "## Objective\n",
    "\n",
    "Explore **linear regression** and **logistic regression** alternatives and come up with the best possible model for the problems, avoiding overfitting. In particular, predict the performance of students from public schools in the state of São Paulo based on socioeconomic data from SARESP (School Performance Assessment System of the State of São Paulo, or Sistema de Avaliação de Rendimento Escolar do Estado de São Paulo) 2021."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "r3XDZRGqEwsk"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "These data were aggregated from [Open Data Platform of the Secretary of Education of the State of São Paulo](https://dados.educacao.sp.gov.br/) (*Portal de Dados Abertos da Secretaria da Educação do Estado de São Paulo*). The dataset is based on two data sources: [SARESP questionnaire](https://dados.educacao.sp.gov.br/dataset/question%C3%A1rios-saresp) and [SARESP test](https://dados.educacao.sp.gov.br/dataset/profici%C3%AAncia-do-sistema-de-avalia%C3%A7%C3%A3o-de-rendimento-escolar-do-estado-de-s%C3%A3o-paulo-saresp-por), conducted in 2021 with students from the 5th and 9th year of Primary School and 3rd year of Highschool. The questionnaire comprehends 63 socio-economical questions, and it is available at the [link](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing)), and the test is composed of questions of Portuguese, Mathematics, and Natural Sciences.\n",
    "\n",
    "\n",
    "**Data Dictionary**:\n",
    "\n",
    "- **CD_ALUNO**: Student ID;\n",
    "\n",
    "- **CODESC**: School ID;\n",
    "\n",
    "- **NOMESC**: School Name;\n",
    "\n",
    "- **RegiaoMetropolitana**: Metropolitan region;\n",
    "\n",
    "- **DE**: Name of the Education Board;\n",
    "\n",
    "- **CODMUN**: City ID;\n",
    "\n",
    "- **MUN**: City name;\n",
    "\n",
    "- **SERIE_ANO**: Scholar year;\n",
    "\n",
    "- **TURMA**: Class;\n",
    "\n",
    "- **TP_SEXO**: Sex (Female/Male);\n",
    "\n",
    "- **DT_NASCIMENTO**: Birth date;\n",
    "\n",
    "- **PERIODO**: Period of study (morning, afternoon, evening);\n",
    "\n",
    "- **Tem_Nec**: Whether student has any special needs (1 = yes, 0 = no);\n",
    "\n",
    "- **NEC_ESP_1** - **NEC_ESP_5**: Student disabilities;\n",
    "\n",
    "- **Tipo_PROVA**: Exam type (A = Enlarged, B = Braile, C = Common);\n",
    "\n",
    "- **QN**: Student answer to the question N (N= 1, ... , 63), see  questions in [questionnaire](https://dados.educacao.sp.gov.br/sites/default/files/Saresp_Quest_2021_Perguntas_Alunos.pdf ) ([English version](https://docs.google.com/document/d/1GUax3wwYxA43d3iNOiyCRImeCHgx8vUJrHlSzzYIXA4/edit?usp=sharing));\n",
    "\n",
    "- **porc_ACERT_lp**: Percentage of correct answers in the Portuguese test;\n",
    "\n",
    "- **porc_ACERT_MAT**: Percentage of correct answers in the Mathematics test;\n",
    "\n",
    "- **porc_ACERT_CIE**: Percentage of correct answers in the Natural Sciences test;\n",
    "\n",
    "- **nivel_profic_lp**: Proficiency level in the Portuguese test;\n",
    "\n",
    "- **nivel_profic_mat**: Proficiency level in the Mathematics test;\n",
    "\n",
    "- **nivel_profic_cie**:  Proficiency level in the Natural Sciences test.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "You must respect the following training/test split:\n",
    "- SARESP_train.csv\n",
    "- SARESP_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FAA8hsZUseO"
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "This part of the assignment aims to predict students' performance on Portuguese, Mathematics, and Natural Sciences tests (target values: `porc_ACERT_lp`, `porc_ACERT_MAT`, and  `porc_ACERT_CIE`) based on their socioeconomic data. Then, at this point, you have to **drop the columns `nivel_profic_lp`, `nivel_profic_mat`** and **`nivel_profic_cie`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d495CmpCltx"
   },
   "source": [
    "### Activities\n",
    "\n",
    "1. (3.5 points) Perform Linear Regression. You should implement your solution and compare it with ```sklearn.linear_model.SGDRegressor``` (linear model fitted by minimizing a regularized empirical loss with SGD, http://scikit-learn.org). Keep in mind that friends don't let friends use testing data for training :-)\n",
    "\n",
    "Note: Before we start an ML project, we always conduct a brief exploratory analysis :D \n",
    "\n",
    "Some factors to consider: Are there any outliers? Are there missing values? How will you handle categorical variables? Are there any features with low correlation with the target variables? What happens if you drop them?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3y0QxxH1KgE1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10789/2935925786.py:9: DtypeWarning: Columns (78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(\"assets/SARESP_train.csv\")\n",
      "/tmp/ipykernel_10789/2935925786.py:11: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  df = df[columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load and preprocess your dataset.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df=pd.read_csv(\"assets/SARESP_train.csv\")\n",
    "columns = set(df.columns) - set(['nivel_profic_lp', 'nivel_profic_mat', 'nivel_profic_cie'])\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_ALUNO</th>\n",
       "      <th>porc_ACERT_MAT</th>\n",
       "      <th>Tem_Nec</th>\n",
       "      <th>CODESC</th>\n",
       "      <th>porc_ACERT_CIE</th>\n",
       "      <th>NEC_ESP_5</th>\n",
       "      <th>porc_ACERT_lp</th>\n",
       "      <th>CODMUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.205960e+05</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120596.000000</td>\n",
       "      <td>120596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.734087e+07</td>\n",
       "      <td>52.225829</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>279415.870510</td>\n",
       "      <td>56.928877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.151213</td>\n",
       "      <td>364.349075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.946464e+06</td>\n",
       "      <td>21.262466</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>394245.824543</td>\n",
       "      <td>18.441383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.730825</td>\n",
       "      <td>220.098318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.739548e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.529711e+07</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15568.000000</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.700000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.712102e+07</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35178.000000</td>\n",
       "      <td>58.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.910558e+07</td>\n",
       "      <td>66.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>901573.000000</td>\n",
       "      <td>70.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.200000</td>\n",
       "      <td>582.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.796186e+07</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>926103.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>793.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CD_ALUNO  porc_ACERT_MAT        Tem_Nec         CODESC  \\\n",
       "count  1.205960e+05   120596.000000  120596.000000  120596.000000   \n",
       "mean   2.734087e+07       52.225829       0.019818  279415.870510   \n",
       "std    2.946464e+06       21.262466       0.139376  394245.824543   \n",
       "min    1.739548e+07        0.000000       0.000000      24.000000   \n",
       "25%    2.529711e+07       37.500000       0.000000   15568.000000   \n",
       "50%    2.712102e+07       50.000000       0.000000   35178.000000   \n",
       "75%    2.910558e+07       66.700000       0.000000  901573.000000   \n",
       "max    3.796186e+07      100.000000       1.000000  926103.000000   \n",
       "\n",
       "       porc_ACERT_CIE  NEC_ESP_5  porc_ACERT_lp         CODMUN  \n",
       "count   120596.000000        0.0  120596.000000  120596.000000  \n",
       "mean        56.928877        NaN      60.151213     364.349075  \n",
       "std         18.441383        NaN      21.730825     220.098318  \n",
       "min          0.000000        NaN       0.000000     100.000000  \n",
       "25%         45.800000        NaN      41.700000     100.000000  \n",
       "50%         58.300000        NaN      62.500000     336.000000  \n",
       "75%         70.800000        NaN      79.200000     582.000000  \n",
       "max        100.000000        NaN     100.000000     793.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CD_ALUNO',\n",
       " 'CODESC',\n",
       " 'CODMUN',\n",
       " 'DE',\n",
       " 'DT_NASCIMENTO',\n",
       " 'MUN',\n",
       " 'NEC_ESP_1',\n",
       " 'NEC_ESP_2',\n",
       " 'NEC_ESP_3',\n",
       " 'NEC_ESP_4',\n",
       " 'NEC_ESP_5',\n",
       " 'NOMESC',\n",
       " 'PERIODO',\n",
       " 'Q1',\n",
       " 'Q10',\n",
       " 'Q11',\n",
       " 'Q12',\n",
       " 'Q13',\n",
       " 'Q14',\n",
       " 'Q15',\n",
       " 'Q16',\n",
       " 'Q17',\n",
       " 'Q18',\n",
       " 'Q19',\n",
       " 'Q2',\n",
       " 'Q20',\n",
       " 'Q21',\n",
       " 'Q22',\n",
       " 'Q23',\n",
       " 'Q24',\n",
       " 'Q25',\n",
       " 'Q26',\n",
       " 'Q27',\n",
       " 'Q28',\n",
       " 'Q29',\n",
       " 'Q3',\n",
       " 'Q30',\n",
       " 'Q31',\n",
       " 'Q32',\n",
       " 'Q33',\n",
       " 'Q34',\n",
       " 'Q35',\n",
       " 'Q36',\n",
       " 'Q37',\n",
       " 'Q38',\n",
       " 'Q39',\n",
       " 'Q4',\n",
       " 'Q40',\n",
       " 'Q41',\n",
       " 'Q42',\n",
       " 'Q43',\n",
       " 'Q44',\n",
       " 'Q45',\n",
       " 'Q46',\n",
       " 'Q47',\n",
       " 'Q48',\n",
       " 'Q49',\n",
       " 'Q5',\n",
       " 'Q50',\n",
       " 'Q51',\n",
       " 'Q52',\n",
       " 'Q53',\n",
       " 'Q54',\n",
       " 'Q55',\n",
       " 'Q56',\n",
       " 'Q57',\n",
       " 'Q58',\n",
       " 'Q59',\n",
       " 'Q6',\n",
       " 'Q60',\n",
       " 'Q61',\n",
       " 'Q62',\n",
       " 'Q63',\n",
       " 'Q7',\n",
       " 'Q8',\n",
       " 'Q9',\n",
       " 'RegiaoMetropolitana',\n",
       " 'SERIE_ANO',\n",
       " 'TP_SEXO',\n",
       " 'TURMA',\n",
       " 'Tem_Nec',\n",
       " 'Tipo_PROVA'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = set(['porc_ACERT_lp', 'porc_ACERT_MAT', 'porc_ACERT_CIE'])\n",
    "featur_columns = columns - target_columns\n",
    "\n",
    "featurs = df[featur_columns]\n",
    "targets = df[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9cpdif9JxFR"
   },
   "outputs": [],
   "source": [
    "# TODO: Linear Regression. Implement your solution. You cannot use scikit-learn, Keras/TensorFlow, or PyTorch libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4nZrMr_C2X7"
   },
   "outputs": [],
   "source": [
    "# TODO: Linear Regression. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBNZQNImKQeo"
   },
   "source": [
    "\n",
    "> What are the conclusions? (1-2 paragraphs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADxPBRhuK_Vq"
   },
   "source": [
    "2. (1 point) Use different Gradient Descent (GD) learning rates when optimizing. Compare the GD-based solutions with Normal Equation. What are the conclusions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSZ1pLItNVbU"
   },
   "outputs": [],
   "source": [
    "# TODO: Gradient Descent (GD) with 3 different learning rates. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrPl7jKgJPW6"
   },
   "source": [
    "\n",
    "3. (0.75 point) Sometimes, we need some more complex function to make good prediction. Devise and evaluate a Polynomial Linear Regression model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjGbg41PMHR9"
   },
   "outputs": [],
   "source": [
    "# TODO: Complex model. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBLKtosaLaCw"
   },
   "source": [
    "*texto em itálico*\n",
    " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldSh1vtWK5Zk"
   },
   "source": [
    "4. (0.5) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg7aNkl_LG4P"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the cost function vs. number of iterations in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfR862UoK9j6"
   },
   "outputs": [],
   "source": [
    "*texto em itálico*\n",
    " > What are the conclusions? What are the actions after such analyses? (1-2 paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xij-E5UUseS"
   },
   "source": [
    "5. (0.25 point) Pick **your best model**, based on your validation set, and predict the target values for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_PobUahUseS"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCJuwjrAUseS"
   },
   "source": [
    "Now, this part of the assignment aims to predict students' proeficiency level on Portuguese, Mathematics, and Natural Sciences (target values: `nivel_profic_lp`, `nivel_profic_mat` and `nivel_profic_cie`) based on their socioeconomic data. Then, you have to **drop the columns `porc_ACERT_lp`,  `porc_ACERT_MAT`** and  **`porc_ACERT_CIE`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joYtn8avUseS"
   },
   "source": [
    "### Activities\n",
    "\n",
    "1. (2.75 points) Perform Multinomial Logistic Regression (_i.e._, softmax regression). It is a generalization of Logistic Regression to the case where we want to handle multiple classes. Try different combinations of features, dropping the ones less correlated to the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-36Dt2V_UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Multinomial Logistic Regression. You can use scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQj3oImUUseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb1KNEqLUseT"
   },
   "source": [
    "2. (0.5 point) Plot the cost function vs. number of epochs in the training/validation set and analyze the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfECeHi3UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the cost function vs. number of iterations in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IM4mx23UseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqlv9-6OUseT"
   },
   "source": [
    "3. (0.75 point) Pick **your best model** and plot the confusion matrix in the **test set**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jdyJuS0UseT"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the confusion matrix. You can use scikit-learn, seaborn, matplotlib libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAmCj0cpUseT"
   },
   "source": [
    "> What are the conclusions? (1-2 paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdSGS4brHnAi"
   },
   "source": [
    "## Deadline\n",
    "\n",
    "Monday, September 19, 11:59 pm. \n",
    "\n",
    "Penalty policy for late submission: You are not encouraged to submit your assignment after due date. However, in case you do, your grade will be penalized as follows:\n",
    "- September 20, 11:59 pm : grade * 0.75\n",
    "- September 21, 11:59 pm : grade * 0.5\n",
    "- September 22, 11:59 pm : grade * 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joN9pvZJIfW5"
   },
   "source": [
    "## Submission\n",
    "\n",
    "On Google Classroom, submit your Jupyter Notebook (in Portuguese or English).\n",
    "\n",
    "**This activity is NOT individual, it must be done in pairs (two-person group).**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
